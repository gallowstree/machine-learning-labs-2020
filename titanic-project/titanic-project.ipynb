{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from math import sqrt, pi, exp \n",
    "\n",
    "if tf.__version__.startswith(\"2.\"):\n",
    "  import tensorflow.compat.v1 as tf\n",
    "  tf.compat.v1.disable_v2_behavior()\n",
    "  tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "all_data = df = pd.read_csv('data_titanic_proyecto.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, train_x, train_y, x_labels=None):\n",
    "        self.x_labels = x_labels\n",
    "        df = self.__init_dataframe(train_x, train_y)\n",
    "        by_class = df.groupby('y')\n",
    "        self.means = by_class.mean()\n",
    "        self.stdvs = by_class.std()\n",
    "        self.cdist = by_class['y'].count() / df.shape[0]\n",
    "\n",
    "    def __init_dataframe(self, train_x, train_y):\n",
    "        df = pd.DataFrame()\n",
    "        df['y'] = train_y\n",
    "        for i,x in enumerate(train_x):\n",
    "            label = self.x_labels[i] if self.x_labels else 'x_' + str(i)\n",
    "            df[label] = x\n",
    "        return df\n",
    "\n",
    "    def predict(self, x_samples):\n",
    "        probs = []\n",
    "        for y in self.cdist.index:\n",
    "            mean = self.means.iloc[y].to_numpy()\n",
    "            std = self.stdvs.iloc[y].to_numpy()\n",
    "            p_x = self.norm_pdf(x_samples, mean, std)\n",
    "            probs.append(self.cdist[y] * np.prod(p_x, axis=1))\n",
    "        probs = np.asarray(probs)\n",
    "        return np.argmax(probs.T,axis=1)\n",
    "\n",
    "    def norm_pdf(self, x, mean, std):\n",
    "        e = np.exp(-((x - mean)**2 / (2 * std**2 )))\n",
    "        return (1 / (sqrt(2*pi) * std)) * e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_x = df.drop('Y', axis=1).T.to_numpy()\n",
    "#train_y = df[['Y']].T.to_numpy()[0]\n",
    "##\n",
    "##\n",
    "#bayes = NaiveBayes(train_x, train_y)\n",
    "#bayes.predict([[5,5],[0,5],[5,0],[1,0],[1,1],[1,2],[2,0],[2,1],[7,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "  class BinaryLogisticRegression:\n",
    "    def __init__(self, x, y):\n",
    "        # Si x es unidimensional, convertir a columna. \n",
    "        # Si x es matriz, asumir una variable por columna.\n",
    "        self.x = x.reshape(-1,1) if x.ndim == 1 else x \n",
    "        self.y = y.reshape(-1, 1)\n",
    "        self.weights = None\n",
    "        self.epochs = None \n",
    "        self.lr = None\n",
    "        self.print_rate = None\n",
    "        self.feed = None\n",
    "        self.batch_size = None\n",
    "        self.batch_iters = None\n",
    "    \n",
    "    def train(self, epochs, lr, batch_size, print_rate=10):\n",
    "        self.print_rate = print_rate\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.batch_size = min(batch_size, self.x.shape[0])\n",
    "        self.batch_iters = int(self.x.shape[0]/self.batch_size)\n",
    "\n",
    "        g = tf.Graph()\n",
    "        with g.as_default():\n",
    "            return self.__do_train()\n",
    "\n",
    "    \n",
    "    def __do_train(self):\n",
    "        placeholder_x = tf.placeholder(tf.float64, [self.batch_size, self.x.shape[1]], \"x\")\n",
    "        placeholder_y = tf.placeholder(tf.float64, [self.batch_size, self.y.shape[1]], \"y\")\n",
    "\n",
    "        with tf.Session() as session:\n",
    "            (weights_op, error_op) = self.__gradient_descent(placeholder_x, placeholder_y)\n",
    "            self.before_training(session.graph, weights_op, error_op)\n",
    "            session.run(tf.global_variables_initializer())    \n",
    "            for epoch in range(1, self.epochs + 1):\n",
    "                for i in range(self.batch_iters):\n",
    "                    start_index  = i*self.batch_size\n",
    "                    end_index = start_index + self.batch_size\n",
    "\n",
    "                    x_batch = np.array(self.x[start_index:end_index])\n",
    "                    y_batch = np.array(self.y[start_index:end_index])\n",
    "                    self.feed = { placeholder_x: x_batch, placeholder_y: y_batch }\n",
    "\n",
    "\n",
    "                    out = session.run([weights_op, error_op], self.feed)\n",
    "                    self.error = out[1]\n",
    "                    self.weights = out[0]\n",
    "                    self.after_epoch(epoch, session)\n",
    "\n",
    "    def __gradient_descent(self, x, y):\n",
    "        n_samples = x.shape[0]\n",
    "        n_independent_vars = x.shape[1] + 1\n",
    "\n",
    "        bias_feature = tf.ones([n_samples, 1], tf.float64)\n",
    "        x = tf.concat([x, bias_feature], axis=1)\n",
    "\n",
    "        initial_weights = tf.zeros([n_independent_vars, 1], tf.float64)\n",
    "        weights = tf.Variable(name=\"Weights\", initial_value=initial_weights)\n",
    "        logits = tf.matmul(x, weights)\n",
    "        error = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=y))\n",
    "        gradients = tf.gradients(error, weights)\n",
    "        adjustment = tf.scalar_mul(-self.lr, gradients[0])\n",
    "        weights = tf.assign(weights, (tf.add(weights, adjustment)))\n",
    "        return (weights, error)\n",
    "\n",
    "    def after_epoch(self, epoch, session):\n",
    "        if epoch % self.print_rate == 0 or epoch == self.epochs:\n",
    "            print(\"epoch:\" + str(epoch) + \" error: \" + str(self.error))\n",
    "    \n",
    "    def before_training(self, graph, weights_op, error_op):\n",
    "        # overridear para inicializar tensorboard, etc\n",
    "        pass\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.hstack((x,np.ones((x.shape[0],1))))\n",
    "        logits = np.matmul(x, self.weights)\n",
    "        logits_ph = tf.placeholder(tf.float32, logits.shape)\n",
    "        with tf.Session() as session:\n",
    "            feed = {logits_ph: logits}\n",
    "            probs = session.run(tf.nn.sigmoid(logits_ph), feed_dict=feed)\n",
    "            y = np.array(list(map(lambda p: 1 if p > 0.5 else 0, probs)))\n",
    "            session.close()\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    }
   ],
   "source": [
    "weather=['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny',\n",
    "'Rainy','Sunny','Overcast','Overcast','Rainy']\n",
    "temp=['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n",
    "\n",
    "play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'weather' : weather,\n",
    "    'temp' : temp,\n",
    "     'play' : play\n",
    "})\n",
    "\n",
    "\n",
    "df.to_dict('index')\n",
    "df[\"Y\"] = df[\"play\"].map( {'No': 0, 'Yes': 1}).astype(int)\n",
    "df[\"weather_encoded\"] = df[\"weather\"].map( {'Overcast': 0, 'Rainy': 1,'Sunny':2}).astype(int)\n",
    "df[\"temp_encoded\"] = df[\"temp\"].map( {'Cool': 0, 'Hot': 1,'Mild':2}).astype(int)\n",
    "\n",
    "\n",
    "x_test = np.array([[0,0],[0,1],[0,2],[1,0],[1,1],[1,2],[2,0],[2,1],[2,2]])\n",
    "y_test = [1,0,1]\n",
    "x_test.reshape(-1,1)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch:500 error: 0.19412925381893273\nepoch:1000 error: 0.18436601554362148\nepoch:1500 error: 0.1808835209881342\nepoch:2000 error: 0.1790850880126646\n"
    }
   ],
   "source": [
    "\n",
    "logreg = BinaryLogisticRegression(df[[\"weather_encoded\",\"temp_encoded\"]].to_numpy(), df[\"Y\"].to_numpy())\n",
    "logreg.train(2000, 0.6, 8, print_rate=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(<map object at 0x7fe87fdb59d0>, dtype=object)"
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitvenvvenv7c8b5f64282a4e90a5603bde2787a492",
   "display_name": "Python 3.8.2 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}