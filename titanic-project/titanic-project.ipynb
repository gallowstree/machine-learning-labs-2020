{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_graphviz, DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from math import sqrt, pi, exp \n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "if tf.__version__.startswith(\"2.\"):\n",
    "  import tensorflow.compat.v1 as tf\n",
    "  tf.compat.v1.disable_v2_behavior()\n",
    "  tf.compat.v1.disable_eager_execution()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "all_data = pd.read_csv('data_titanic_proyecto.csv')\n",
    "# Cada vez que se vuelvan a cargar los datos, necesitaremos volver a transformar\n",
    "transformed_categoric = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio y limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscaremos valores faltantes en todo el dataset para saber si se espera tener que realizar imputación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "PassengerId             0\nName                    0\nAge                   177\nSibSp                   0\nParch                   0\nTicket                  0\nFare                    0\nCabin                 687\nEmbarked                2\npassenger_class         0\npassenger_sex           0\npassenger_survived      0\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 392
    }
   ],
   "source": [
    "all_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que Cabin tiene muchos valores faltantes, por lo que sería difícil realizar imputación, pero podemos utilizar estadística descriptiva para rellenar los valores faltantes en Age y Embarked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos una muestra del data set para familiarizarnos con las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     PassengerId                                         Name   Age  SibSp  \\\n213          214                  Givard, Mr. Hans Kristensen  30.0      0   \n160          161                     Cribb, Mr. John Hatfield  44.0      0   \n726          727  Renouf, Mrs. Peter Henry (Lillian Jefferys)  30.0      3   \n313          314                       Hendekovic, Mr. Ignjac  28.0      0   \n\n     Parch  Ticket     Fare Cabin Embarked passenger_class passenger_sex  \\\n213      0  250646  13.0000   NaN        S          Middle             M   \n160      1  371362  16.1000   NaN        S           Lower             M   \n726      0   31027  21.0000   NaN        S          Middle             F   \n313      0  349243   7.8958   NaN        S           Lower             M   \n\n    passenger_survived  \n213                  N  \n160                  N  \n726                  Y  \n313                  N  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>passenger_class</th>\n      <th>passenger_sex</th>\n      <th>passenger_survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>213</th>\n      <td>214</td>\n      <td>Givard, Mr. Hans Kristensen</td>\n      <td>30.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>250646</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Middle</td>\n      <td>M</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>160</th>\n      <td>161</td>\n      <td>Cribb, Mr. John Hatfield</td>\n      <td>44.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>371362</td>\n      <td>16.1000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Lower</td>\n      <td>M</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>726</th>\n      <td>727</td>\n      <td>Renouf, Mrs. Peter Henry (Lillian Jefferys)</td>\n      <td>30.0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>31027</td>\n      <td>21.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Middle</td>\n      <td>F</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>313</th>\n      <td>314</td>\n      <td>Hendekovic, Mr. Ignjac</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>349243</td>\n      <td>7.8958</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Lower</td>\n      <td>M</td>\n      <td>N</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 393
    }
   ],
   "source": [
    "all_data.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            Age     SibSp     Parch        Fare\nmean  29.699118  0.523008  0.381594   32.204208\nstd   14.526497  1.102743  0.806057   49.693429\nmin    0.420000  0.000000  0.000000    0.000000\n25%   20.125000  0.000000  0.000000    7.910400\n50%   28.000000  0.000000  0.000000   14.454200\n75%   38.000000  1.000000  0.000000   31.000000\nmax   80.000000  8.000000  6.000000  512.329200",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>mean</th>\n      <td>29.699118</td>\n      <td>0.523008</td>\n      <td>0.381594</td>\n      <td>32.204208</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>14.526497</td>\n      <td>1.102743</td>\n      <td>0.806057</td>\n      <td>49.693429</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>20.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>7.910400</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>14.454200</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>38.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>31.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>80.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>512.329200</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 394
    }
   ],
   "source": [
    "all_data.describe().drop('count').drop('PassengerId', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SibSp es la suma del número de hermanos y cónyugues a bordo para el pasajero. \n",
    "\n",
    "Parch es la cantidad de padres e hijos a bordo. \n",
    "\n",
    "Embarked es la inicial del puerto donde embarcaró el pasajero. \n",
    "\n",
    "Vemos que la clase del pasajero es categórica (Upper, Lower, Middle) pero nos interesa su correlación con otras variables, por lo que la cambiaremos a una categórica numérica. Lo mismo con la variable objetivo, passenger_survived y passenger_sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not transformed_categoric:\n",
    "    all_data[\"passenger_class\"].replace({\"Upper\" : 1, \"Middle\" : 2, \"Lower\" : 3}, inplace=True)\n",
    "    all_data[\"passenger_survived\"].replace({\"Y\" : 1, \"N\" : 0}, inplace=True)\n",
    "    all_data[\"passenger_sex\"].replace({\"M\" : 1, \"F\" : 0}, inplace=True)\n",
    "    all_data[\"Embarked\"].replace({\"Q\" : 0, \"C\" : 1, \"S\": 2}, inplace=True)\n",
    "    transformed_categoric = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que hemos transformado esas variables en todo el data set, podemos separarlo en los sets de entrenamiento, validación y prueba. También podremos analizar la correlación gracias a las variables que convertimos a numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "all_data shape (891, 12)\ntrain_set shape (569, 12)\nvalidation_set shape (143, 12)\n"
    }
   ],
   "source": [
    "train_set = test_set = validation_set = None\n",
    "def split_dataset():\n",
    "    global train_set, test_set, validation_set\n",
    "    train_set, test_set = train_test_split(all_data, test_size=0.2, random_state=420*666)\n",
    "    train_set, validation_set = train_test_split(train_set, test_size=0.2, random_state=420*666)\n",
    "    return train_set, validation_set, test_set\n",
    "\n",
    "split_dataset()\n",
    "\n",
    "print(\"all_data shape\", all_data.shape)\n",
    "print(\"train_set shape\", train_set.shape)\n",
    "print(\"validation_set shape\", validation_set.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                    PassengerId       Age     SibSp     Parch      Fare  \\\nPassengerId            1.000000  0.069606  0.038611  0.022055  0.014407   \nAge                    0.069606  1.000000  0.277610  0.162013  0.072028   \nSibSp                  0.038611  0.277610  1.000000  0.412171  0.183415   \nParch                  0.022055  0.162013  0.412171  1.000000  0.190890   \nFare                   0.014407  0.072028  0.183415  0.190890  1.000000   \nEmbarked               0.049909  0.012376  0.083905  0.097895  0.100815   \npassenger_class        0.030610  0.306439  0.050290  0.038240  0.566640   \npassenger_sex          0.069002  0.091986  0.138134  0.259041  0.234383   \npassenger_survived     0.027587  0.087042  0.033621  0.047219  0.299864   \n\n                    Embarked  passenger_class  passenger_sex  \\\nPassengerId         0.049909         0.030610       0.069002   \nAge                 0.012376         0.306439       0.091986   \nSibSp               0.083905         0.050290       0.138134   \nParch               0.097895         0.038240       0.259041   \nFare                0.100815         0.566640       0.234383   \nEmbarked            1.000000         0.006342       0.129316   \npassenger_class     0.006342         1.000000       0.156165   \npassenger_sex       0.129316         0.156165       1.000000   \npassenger_survived  0.146525         0.365862       0.533318   \n\n                    passenger_survived  \nPassengerId                   0.027587  \nAge                           0.087042  \nSibSp                         0.033621  \nParch                         0.047219  \nFare                          0.299864  \nEmbarked                      0.146525  \npassenger_class               0.365862  \npassenger_sex                 0.533318  \npassenger_survived            1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>passenger_class</th>\n      <th>passenger_sex</th>\n      <th>passenger_survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>PassengerId</th>\n      <td>1.000000</td>\n      <td>0.069606</td>\n      <td>0.038611</td>\n      <td>0.022055</td>\n      <td>0.014407</td>\n      <td>0.049909</td>\n      <td>0.030610</td>\n      <td>0.069002</td>\n      <td>0.027587</td>\n    </tr>\n    <tr>\n      <th>Age</th>\n      <td>0.069606</td>\n      <td>1.000000</td>\n      <td>0.277610</td>\n      <td>0.162013</td>\n      <td>0.072028</td>\n      <td>0.012376</td>\n      <td>0.306439</td>\n      <td>0.091986</td>\n      <td>0.087042</td>\n    </tr>\n    <tr>\n      <th>SibSp</th>\n      <td>0.038611</td>\n      <td>0.277610</td>\n      <td>1.000000</td>\n      <td>0.412171</td>\n      <td>0.183415</td>\n      <td>0.083905</td>\n      <td>0.050290</td>\n      <td>0.138134</td>\n      <td>0.033621</td>\n    </tr>\n    <tr>\n      <th>Parch</th>\n      <td>0.022055</td>\n      <td>0.162013</td>\n      <td>0.412171</td>\n      <td>1.000000</td>\n      <td>0.190890</td>\n      <td>0.097895</td>\n      <td>0.038240</td>\n      <td>0.259041</td>\n      <td>0.047219</td>\n    </tr>\n    <tr>\n      <th>Fare</th>\n      <td>0.014407</td>\n      <td>0.072028</td>\n      <td>0.183415</td>\n      <td>0.190890</td>\n      <td>1.000000</td>\n      <td>0.100815</td>\n      <td>0.566640</td>\n      <td>0.234383</td>\n      <td>0.299864</td>\n    </tr>\n    <tr>\n      <th>Embarked</th>\n      <td>0.049909</td>\n      <td>0.012376</td>\n      <td>0.083905</td>\n      <td>0.097895</td>\n      <td>0.100815</td>\n      <td>1.000000</td>\n      <td>0.006342</td>\n      <td>0.129316</td>\n      <td>0.146525</td>\n    </tr>\n    <tr>\n      <th>passenger_class</th>\n      <td>0.030610</td>\n      <td>0.306439</td>\n      <td>0.050290</td>\n      <td>0.038240</td>\n      <td>0.566640</td>\n      <td>0.006342</td>\n      <td>1.000000</td>\n      <td>0.156165</td>\n      <td>0.365862</td>\n    </tr>\n    <tr>\n      <th>passenger_sex</th>\n      <td>0.069002</td>\n      <td>0.091986</td>\n      <td>0.138134</td>\n      <td>0.259041</td>\n      <td>0.234383</td>\n      <td>0.129316</td>\n      <td>0.156165</td>\n      <td>1.000000</td>\n      <td>0.533318</td>\n    </tr>\n    <tr>\n      <th>passenger_survived</th>\n      <td>0.027587</td>\n      <td>0.087042</td>\n      <td>0.033621</td>\n      <td>0.047219</td>\n      <td>0.299864</td>\n      <td>0.146525</td>\n      <td>0.365862</td>\n      <td>0.533318</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 397
    }
   ],
   "source": [
    "train_set.corr().abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que Age tiene la mayor correlación con passenger_class, por lo que agruparemos para calcular la mediana de edad por clase. Otro dato interesante sería la mediana de edad por sexo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Medianas\npassenger_class\n1    36.0\n2    30.0\n3    25.0\nName: Age, dtype: float64 \n\npassenger_sex\n0    27.0\n1    29.0\nName: Age, dtype: float64 \n\n\nMedias\npassenger_class\n1    36.503590\n2    29.708276\n3    26.054330\nName: Age, dtype: float64 \n\npassenger_sex\n0    28.021802\n1    30.643860\nName: Age, dtype: float64 \n\n"
    }
   ],
   "source": [
    "print(\"Medianas\")\n",
    "print(train_set.groupby('passenger_class').median()['Age'], \"\\n\")\n",
    "print(train_set.groupby('passenger_sex').median()['Age'], \"\\n\")\n",
    "\n",
    "print(\"\\nMedias\")\n",
    "print(train_set.groupby('passenger_class').mean()['Age'], \"\\n\")\n",
    "print(train_set.groupby('passenger_sex').mean()['Age'], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos un aumento significativo en la mediana de la edad conforme la clase aumenta. También vemos que las mujeres son ligeramente más jóvenes. Ahora veamos cómo se comportan las edades al agrupar por ambos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "passenger_class  passenger_sex\n1                0                33.0\n                 1                39.0\n2                0                28.0\n                 1                30.0\n3                0                22.0\n                 1                26.0\nName: Age, dtype: float64"
     },
     "metadata": {},
     "execution_count": 399
    }
   ],
   "source": [
    "median_ages_by_class_and_sex = train_set.groupby(['passenger_class', 'passenger_sex']).median()['Age']\n",
    "median_ages_by_class_and_sex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos datos podemos rellenar la edad de los faltantes de cada grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2.0"
     },
     "metadata": {},
     "execution_count": 407
    }
   ],
   "source": [
    "for pclass in range(1,4):\n",
    "    for sex in range(0,2):\n",
    "        condition = (all_data['passenger_class'] == pclass) & (all_data['passenger_sex'] == sex)\n",
    "        all_data['Age'][condition] = all_data['Age'][condition].fillna(median_ages_by_class_and_sex[pclass][sex])\n",
    "\n",
    "all_data['Age'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos la moda de Embarked para rellenar los dos faltanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "execution_count": 408
    }
   ],
   "source": [
    "all_data['Embarked'] = all_data['Embarked'].fillna(test_set['Embarked'].mode().any())\n",
    "all_data['Embarked'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n0\n0\n0\n0\n0\n"
    }
   ],
   "source": [
    "\n",
    "split_dataset() # actualizamos nuestros subsets con los faltantes rellenados\n",
    "\n",
    "print(test_set['Age'].isna().sum())\n",
    "print(test_set['Embarked'].isna().sum())\n",
    "print(validation_set['Age'].isna().sum())\n",
    "print(validation_set['Embarked'].isna().sum())\n",
    "print(train_set['Age'].isna().sum())\n",
    "print(train_set['Embarked'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de predicción individuales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, train_x, train_y, x_labels=None):\n",
    "        self.x_labels = x_labels\n",
    "        df = self.__init_dataframe(train_x, train_y)\n",
    "        by_class = df.groupby('y')\n",
    "        self.means = by_class.mean()\n",
    "        self.stdvs = by_class.std()\n",
    "        self.cdist = by_class['y'].count() / df.shape[0]\n",
    "\n",
    "    def __init_dataframe(self, train_x, train_y):\n",
    "        df = pd.DataFrame()\n",
    "        df['y'] = train_y\n",
    "        for i,x in enumerate(train_x):\n",
    "            label = self.x_labels[i] if self.x_labels else 'x_' + str(i)\n",
    "            df[label] = x\n",
    "        return df\n",
    "\n",
    "    def predict(self, x_samples):\n",
    "        probs = []\n",
    "        for y in self.cdist.index:\n",
    "            mean = self.means.iloc[y].to_numpy()\n",
    "            std = self.stdvs.iloc[y].to_numpy()\n",
    "            p_x = self.norm_pdf(x_samples, mean, std)\n",
    "            probs.append(self.cdist[y] * np.prod(p_x, axis=1))\n",
    "        probs = np.asarray(probs)\n",
    "        return np.argmax(probs.T,axis=1)\n",
    "\n",
    "    def norm_pdf(self, x, mean, std):\n",
    "        e = np.exp(-((x - mean)**2 / (2 * std**2 )))\n",
    "        return (1 / (sqrt(2*pi) * std)) * e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador binario basado en regresión logísitca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "  class BinaryLogisticRegression:\n",
    "    def __init__(self, x, y):\n",
    "        # Si x es unidimensional, convertir a columna. \n",
    "        # Si x es matriz, asumir una variable por columna.\n",
    "        self.x = x.reshape(-1,1) if x.ndim == 1 else x \n",
    "        self.y = y.reshape(-1, 1)\n",
    "        self.weights = None\n",
    "        self.epochs = None \n",
    "        self.lr = None\n",
    "        self.print_rate = None\n",
    "        self.feed = None\n",
    "        self.batch_size = None\n",
    "        self.batch_iters = None\n",
    "    \n",
    "    def train(self, epochs, lr, batch_size, print_rate=10):\n",
    "        self.print_rate = print_rate\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.batch_size = min(batch_size, self.x.shape[0])\n",
    "        self.batch_iters = int(self.x.shape[0]/self.batch_size)\n",
    "\n",
    "        g = tf.Graph()\n",
    "        with g.as_default():\n",
    "            return self.__do_train()\n",
    "\n",
    "    \n",
    "    def __do_train(self):\n",
    "        placeholder_x = tf.placeholder(tf.float64, [self.batch_size, self.x.shape[1]], \"x\")\n",
    "        placeholder_y = tf.placeholder(tf.float64, [self.batch_size, self.y.shape[1]], \"y\")\n",
    "\n",
    "        with tf.Session() as session:\n",
    "            (weights_op, error_op) = self.__gradient_descent(placeholder_x, placeholder_y)\n",
    "            self.before_training(session.graph, weights_op, error_op)\n",
    "            session.run(tf.global_variables_initializer())    \n",
    "            for epoch in range(1, self.epochs + 1):\n",
    "                for i in range(self.batch_iters):\n",
    "                    start_index  = i*self.batch_size\n",
    "                    end_index = start_index + self.batch_size\n",
    "\n",
    "                    x_batch = np.array(self.x[start_index:end_index])\n",
    "                    y_batch = np.array(self.y[start_index:end_index])\n",
    "                    self.feed = { placeholder_x: x_batch, placeholder_y: y_batch }\n",
    "\n",
    "\n",
    "                    out = session.run([weights_op, error_op], self.feed)\n",
    "                    self.error = out[1]\n",
    "                    self.weights = out[0]\n",
    "                    self.after_epoch(epoch, session)\n",
    "\n",
    "    def __gradient_descent(self, x, y):\n",
    "        n_samples = x.shape[0]\n",
    "        n_independent_vars = x.shape[1] + 1\n",
    "\n",
    "        bias_feature = tf.ones([n_samples, 1], tf.float64)\n",
    "        x = tf.concat([x, bias_feature], axis=1)\n",
    "\n",
    "        initial_weights = tf.zeros([n_independent_vars, 1], tf.float64)\n",
    "        weights = tf.Variable(name=\"Weights\", initial_value=initial_weights)\n",
    "        logits = tf.matmul(x, weights)\n",
    "        error = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=y))\n",
    "        gradients = tf.gradients(error, weights)\n",
    "        adjustment = tf.scalar_mul(-self.lr, gradients[0])\n",
    "        weights = tf.assign(weights, (tf.add(weights, adjustment)))\n",
    "        return (weights, error)\n",
    "\n",
    "    def after_epoch(self, epoch, session):\n",
    "        if epoch % self.print_rate == 0 or epoch == self.epochs:\n",
    "            print(\"epoch:\" + str(epoch) + \" error: \" + str(self.error))\n",
    "    \n",
    "    def before_training(self, graph, weights_op, error_op):\n",
    "        # overridear para inicializar tensorboard, etc\n",
    "        pass\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.hstack((x,np.ones((x.shape[0],1))))\n",
    "        logits = np.matmul(x, self.weights)\n",
    "        logits_ph = tf.placeholder(tf.float32, logits.shape)\n",
    "        with tf.Session() as session:\n",
    "            feed = {logits_ph: logits}\n",
    "            probs = session.run(tf.nn.sigmoid(logits_ph), feed_dict=feed)\n",
    "            session.close()\n",
    "        y = np.array(list(map(lambda p: 1 if p > 0.5 else 0, probs)))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# logreg = BinaryLogisticRegression(df[[\"weather_encoded\",\"temp_encoded\"]].to_numpy(), df[\"Y\"].to_numpy())\n",
    "# logreg.train(2000, 0.6, 8, print_rate=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit Learn DecisionTreeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree(x, y):\n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    decision_tree.fit(x, y)\n",
    "    return decision_tree\n",
    "\n",
    "# gv_data = export_graphviz(decision_tree, out_file=None,\n",
    "#                                         feature_names=[\"weather\",\"temp\"],\n",
    "#                                         class_names=[\"not_play\",\"play\"],\n",
    "#                                         filled=True, rounded=True,\n",
    "#                                         special_characters=True)\n",
    "# graph = graphviz.Source(gv_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit Learn Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(x,y):\n",
    "    svm_classifier = svm.SVC(kernel='linear')\n",
    "    svm_classifier.fit(x,y)\n",
    "    return svm_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitvenvvenv7c8b5f64282a4e90a5603bde2787a492",
   "display_name": "Python 3.8.2 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}