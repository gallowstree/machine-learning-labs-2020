{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_graphviz, DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from math import sqrt, pi, exp \n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "if tf.__version__.startswith(\"2.\"):\n",
    "  import tensorflow.compat.v1 as tf\n",
    "  tf.compat.v1.disable_v2_behavior()\n",
    "  tf.compat.v1.disable_eager_execution()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "all_data = pd.read_csv('data_titanic_proyecto.csv')\n",
    "# train_set, test_set = train_test_split(all_data, test_size=0.2)\n",
    "# train_set, validation_set = train_test_split(train_set, test_size=0.2)\n",
    "# \n",
    "# print(\"all_data shape\", all_data.shape)\n",
    "# print(\"train_set shape\", train_set.shape)\n",
    "# print(\"validation_set shape\", validation_set.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio y limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscaremos valores faltantes en todo el dataset para saber si se espera tener que realizar imputación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "PassengerId             0\nName                    0\nAge                   177\nSibSp                   0\nParch                   0\nTicket                  0\nFare                    0\nCabin                 687\nEmbarked                2\npassenger_class         0\npassenger_sex           0\npassenger_survived      0\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "all_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que Cabin tiene muchos valores faltantes, por lo que sería difícil realizar imputación, pero podemos utilizar estadística descriptiva para rellenar los valores faltantes en edad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos una muestra del data set para familiarizarnos con las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     PassengerId                                      Name   Age  SibSp  \\\n655          656                 Hickman, Mr. Leonard Mark  24.0      2   \n552          553                      O'Brien, Mr. Timothy   NaN      0   \n43            44  Laroche, Miss. Simonne Marie Anne Andree   3.0      1   \n802          803       Carter, Master. William Thornton II  11.0      1   \n\n     Parch         Ticket      Fare    Cabin Embarked passenger_class  \\\n655      0   S.O.C. 14879   73.5000      NaN        S          Middle   \n552      0         330979    7.8292      NaN        Q           Lower   \n43       2  SC/Paris 2123   41.5792      NaN        C          Middle   \n802      2         113760  120.0000  B96 B98        S           Upper   \n\n    passenger_sex passenger_survived  \n655             M                  N  \n552             M                  N  \n43              F                  Y  \n802             M                  Y  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>passenger_class</th>\n      <th>passenger_sex</th>\n      <th>passenger_survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>655</th>\n      <td>656</td>\n      <td>Hickman, Mr. Leonard Mark</td>\n      <td>24.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>S.O.C. 14879</td>\n      <td>73.5000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Middle</td>\n      <td>M</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>552</th>\n      <td>553</td>\n      <td>O'Brien, Mr. Timothy</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330979</td>\n      <td>7.8292</td>\n      <td>NaN</td>\n      <td>Q</td>\n      <td>Lower</td>\n      <td>M</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>44</td>\n      <td>Laroche, Miss. Simonne Marie Anne Andree</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>SC/Paris 2123</td>\n      <td>41.5792</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>Middle</td>\n      <td>F</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>802</th>\n      <td>803</td>\n      <td>Carter, Master. William Thornton II</td>\n      <td>11.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>113760</td>\n      <td>120.0000</td>\n      <td>B96 B98</td>\n      <td>S</td>\n      <td>Upper</td>\n      <td>M</td>\n      <td>Y</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "source": [
    "all_data.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SibSp es la suma del número de hermanos y cónyugues a bordo para el pasajero. \n",
    "\n",
    "Parch es la cantidad de padres e hijos a bordo. \n",
    "\n",
    "Embarked es la inicial del puerto donde embarcaró el pasajero. \n",
    "\n",
    "Vemos que la clase del pasajero es categórica (Upper, Lower, Middle) pero nos interesa su correlación con otras variables, por lo que la cambiaremos a una categórica numérica. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     PassengerId                          Name   Age  SibSp  Parch  \\\n574          575  Rush, Mr. Alfred George John  16.0      0      0   \n\n         Ticket  Fare Cabin Embarked  passenger_class passenger_sex  \\\n574  A/4. 20589  8.05   NaN        S              NaN             M   \n\n    passenger_survived  \n574                  N  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>passenger_class</th>\n      <th>passenger_sex</th>\n      <th>passenger_survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>574</th>\n      <td>575</td>\n      <td>Rush, Mr. Alfred George John</td>\n      <td>16.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>A/4. 20589</td>\n      <td>8.05</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>N</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "all_data.replace({\"Upper\" : 1, \"Middle\" : 2, \"Lower\" : 3}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "PassengerId      PassengerId        1.000000\n                 Age                0.036847\n                 SibSp              0.057527\n                 Parch              0.001652\n                 Fare               0.012658\n                 passenger_class    0.035144\nAge              PassengerId        0.036847\n                 Age                1.000000\n                 SibSp              0.308247\n                 Parch              0.189119\n                 Fare               0.096067\n                 passenger_class    0.369226\nSibSp            PassengerId        0.057527\n                 Age                0.308247\n                 SibSp              1.000000\n                 Parch              0.414838\n                 Fare               0.159651\n                 passenger_class    0.083081\nParch            PassengerId        0.001652\n                 Age                0.189119\n                 SibSp              0.414838\n                 Parch              1.000000\n                 Fare               0.216225\n                 passenger_class    0.018443\nFare             PassengerId        0.012658\n                 Age                0.096067\n                 SibSp              0.159651\n                 Parch              0.216225\n                 Fare               1.000000\n                 passenger_class    0.549500\npassenger_class  PassengerId        0.035144\n                 Age                0.369226\n                 SibSp              0.083081\n                 Parch              0.018443\n                 Fare               0.549500\n                 passenger_class    1.000000\ndtype: float64"
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "all_data.corr().abs().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, train_x, train_y, x_labels=None):\n",
    "        self.x_labels = x_labels\n",
    "        df = self.__init_dataframe(train_x, train_y)\n",
    "        by_class = df.groupby('y')\n",
    "        self.means = by_class.mean()\n",
    "        self.stdvs = by_class.std()\n",
    "        self.cdist = by_class['y'].count() / df.shape[0]\n",
    "\n",
    "    def __init_dataframe(self, train_x, train_y):\n",
    "        df = pd.DataFrame()\n",
    "        df['y'] = train_y\n",
    "        for i,x in enumerate(train_x):\n",
    "            label = self.x_labels[i] if self.x_labels else 'x_' + str(i)\n",
    "            df[label] = x\n",
    "        return df\n",
    "\n",
    "    def predict(self, x_samples):\n",
    "        probs = []\n",
    "        for y in self.cdist.index:\n",
    "            mean = self.means.iloc[y].to_numpy()\n",
    "            std = self.stdvs.iloc[y].to_numpy()\n",
    "            p_x = self.norm_pdf(x_samples, mean, std)\n",
    "            probs.append(self.cdist[y] * np.prod(p_x, axis=1))\n",
    "        probs = np.asarray(probs)\n",
    "        return np.argmax(probs.T,axis=1)\n",
    "\n",
    "    def norm_pdf(self, x, mean, std):\n",
    "        e = np.exp(-((x - mean)**2 / (2 * std**2 )))\n",
    "        return (1 / (sqrt(2*pi) * std)) * e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_x = df.drop('Y', axis=1).T.to_numpy()\n",
    "#train_y = df[['Y']].T.to_numpy()[0]\n",
    "##\n",
    "##\n",
    "#bayes = NaiveBayes(train_x, train_y)\n",
    "#bayes.predict([[5,5],[0,5],[5,0],[1,0],[1,1],[1,2],[2,0],[2,1],[7,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador binario basado en regresión logísitca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "  class BinaryLogisticRegression:\n",
    "    def __init__(self, x, y):\n",
    "        # Si x es unidimensional, convertir a columna. \n",
    "        # Si x es matriz, asumir una variable por columna.\n",
    "        self.x = x.reshape(-1,1) if x.ndim == 1 else x \n",
    "        self.y = y.reshape(-1, 1)\n",
    "        self.weights = None\n",
    "        self.epochs = None \n",
    "        self.lr = None\n",
    "        self.print_rate = None\n",
    "        self.feed = None\n",
    "        self.batch_size = None\n",
    "        self.batch_iters = None\n",
    "    \n",
    "    def train(self, epochs, lr, batch_size, print_rate=10):\n",
    "        self.print_rate = print_rate\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.batch_size = min(batch_size, self.x.shape[0])\n",
    "        self.batch_iters = int(self.x.shape[0]/self.batch_size)\n",
    "\n",
    "        g = tf.Graph()\n",
    "        with g.as_default():\n",
    "            return self.__do_train()\n",
    "\n",
    "    \n",
    "    def __do_train(self):\n",
    "        placeholder_x = tf.placeholder(tf.float64, [self.batch_size, self.x.shape[1]], \"x\")\n",
    "        placeholder_y = tf.placeholder(tf.float64, [self.batch_size, self.y.shape[1]], \"y\")\n",
    "\n",
    "        with tf.Session() as session:\n",
    "            (weights_op, error_op) = self.__gradient_descent(placeholder_x, placeholder_y)\n",
    "            self.before_training(session.graph, weights_op, error_op)\n",
    "            session.run(tf.global_variables_initializer())    \n",
    "            for epoch in range(1, self.epochs + 1):\n",
    "                for i in range(self.batch_iters):\n",
    "                    start_index  = i*self.batch_size\n",
    "                    end_index = start_index + self.batch_size\n",
    "\n",
    "                    x_batch = np.array(self.x[start_index:end_index])\n",
    "                    y_batch = np.array(self.y[start_index:end_index])\n",
    "                    self.feed = { placeholder_x: x_batch, placeholder_y: y_batch }\n",
    "\n",
    "\n",
    "                    out = session.run([weights_op, error_op], self.feed)\n",
    "                    self.error = out[1]\n",
    "                    self.weights = out[0]\n",
    "                    self.after_epoch(epoch, session)\n",
    "\n",
    "    def __gradient_descent(self, x, y):\n",
    "        n_samples = x.shape[0]\n",
    "        n_independent_vars = x.shape[1] + 1\n",
    "\n",
    "        bias_feature = tf.ones([n_samples, 1], tf.float64)\n",
    "        x = tf.concat([x, bias_feature], axis=1)\n",
    "\n",
    "        initial_weights = tf.zeros([n_independent_vars, 1], tf.float64)\n",
    "        weights = tf.Variable(name=\"Weights\", initial_value=initial_weights)\n",
    "        logits = tf.matmul(x, weights)\n",
    "        error = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=y))\n",
    "        gradients = tf.gradients(error, weights)\n",
    "        adjustment = tf.scalar_mul(-self.lr, gradients[0])\n",
    "        weights = tf.assign(weights, (tf.add(weights, adjustment)))\n",
    "        return (weights, error)\n",
    "\n",
    "    def after_epoch(self, epoch, session):\n",
    "        if epoch % self.print_rate == 0 or epoch == self.epochs:\n",
    "            print(\"epoch:\" + str(epoch) + \" error: \" + str(self.error))\n",
    "    \n",
    "    def before_training(self, graph, weights_op, error_op):\n",
    "        # overridear para inicializar tensorboard, etc\n",
    "        pass\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.hstack((x,np.ones((x.shape[0],1))))\n",
    "        logits = np.matmul(x, self.weights)\n",
    "        logits_ph = tf.placeholder(tf.float32, logits.shape)\n",
    "        with tf.Session() as session:\n",
    "            feed = {logits_ph: logits}\n",
    "            probs = session.run(tf.nn.sigmoid(logits_ph), feed_dict=feed)\n",
    "            session.close()\n",
    "        y = np.array(list(map(lambda p: 1 if p > 0.5 else 0, probs)))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    }
   ],
   "source": [
    "weather=['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny',\n",
    "'Rainy','Sunny','Overcast','Overcast','Rainy']\n",
    "temp=['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n",
    "\n",
    "play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'weather' : weather,\n",
    "    'temp' : temp,\n",
    "     'play' : play\n",
    "})\n",
    "\n",
    "\n",
    "df.to_dict('index')\n",
    "df[\"Y\"] = df[\"play\"].map( {'No': 0, 'Yes': 1}).astype(int)\n",
    "df[\"weather_encoded\"] = df[\"weather\"].map( {'Overcast': 0, 'Rainy': 1,'Sunny':2}).astype(int)\n",
    "df[\"temp_encoded\"] = df[\"temp\"].map( {'Cool': 0, 'Hot': 1,'Mild':2}).astype(int)\n",
    "\n",
    "\n",
    "x_test = np.array([[0,0],[0,1],[0,2],[1,0],[1,1],[1,2],[2,0],[2,1],[2,2]])\n",
    "y_test = [1,0,1]\n",
    "x_test.reshape(-1,1)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch:500 error: 0.19412925381893273\nepoch:1000 error: 0.18436601554362148\nepoch:1500 error: 0.1808835209881342\nepoch:2000 error: 0.1790850880126646\n"
    }
   ],
   "source": [
    "\n",
    "logreg = BinaryLogisticRegression(df[[\"weather_encoded\",\"temp_encoded\"]].to_numpy(), df[\"Y\"].to_numpy())\n",
    "logreg.train(2000, 0.6, 8, print_rate=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1, 1, 1, 0, 1, 1, 0, 0, 0])"
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit Learn DecisionTreeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<graphviz.files.Source at 0x7fe7e3ab2d00>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"553pt\" height=\"552pt\"\n viewBox=\"0.00 0.00 553.00 552.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 548)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-548 549,-548 549,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#a7d3f3\" stroke=\"black\" d=\"M216,-544C216,-544 142,-544 142,-544 136,-544 130,-538 130,-532 130,-532 130,-473 130,-473 130,-467 136,-461 142,-461 142,-461 216,-461 216,-461 222,-461 228,-467 228,-473 228,-473 228,-532 228,-532 228,-538 222,-544 216,-544\"/>\n<text text-anchor=\"start\" x=\"138\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">weather ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"143.5\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.459</text>\n<text text-anchor=\"start\" x=\"138\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 14</text>\n<text text-anchor=\"start\" x=\"139.5\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 9]</text>\n<text text-anchor=\"start\" x=\"143\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = play</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M153.5,-417.5C153.5,-417.5 82.5,-417.5 82.5,-417.5 76.5,-417.5 70.5,-411.5 70.5,-405.5 70.5,-405.5 70.5,-361.5 70.5,-361.5 70.5,-355.5 76.5,-349.5 82.5,-349.5 82.5,-349.5 153.5,-349.5 153.5,-349.5 159.5,-349.5 165.5,-355.5 165.5,-361.5 165.5,-361.5 165.5,-405.5 165.5,-405.5 165.5,-411.5 159.5,-417.5 153.5,-417.5\"/>\n<text text-anchor=\"start\" x=\"90\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"80.5\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"78.5\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4]</text>\n<text text-anchor=\"start\" x=\"82\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = play</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M157.84,-460.91C152.08,-449.87 145.84,-437.9 140.04,-426.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"143.02,-424.92 135.29,-417.67 136.81,-428.15 143.02,-424.92\"/>\n<text text-anchor=\"middle\" x=\"127.79\" y=\"-437.81\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M286,-425C286,-425 196,-425 196,-425 190,-425 184,-419 184,-413 184,-413 184,-354 184,-354 184,-348 190,-342 196,-342 196,-342 286,-342 286,-342 292,-342 298,-348 298,-354 298,-354 298,-413 298,-413 298,-419 292,-425 286,-425\"/>\n<text text-anchor=\"start\" x=\"208.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">temp ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"213\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"200\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"start\" x=\"201.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 5]</text>\n<text text-anchor=\"start\" x=\"192\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = not_play</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M200.51,-460.91C205.13,-452.2 210.05,-442.9 214.83,-433.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"217.94,-435.5 219.53,-425.02 211.75,-432.22 217.94,-435.5\"/>\n<text text-anchor=\"middle\" x=\"226.87\" y=\"-445.22\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M216,-306C216,-306 142,-306 142,-306 136,-306 130,-300 130,-294 130,-294 130,-235 130,-235 130,-229 136,-223 142,-223 142,-223 216,-223 216,-223 222,-223 228,-229 228,-235 228,-235 228,-294 228,-294 228,-300 222,-306 216,-306\"/>\n<text text-anchor=\"start\" x=\"138\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">weather ≤ 1.5</text>\n<text text-anchor=\"start\" x=\"143.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"141.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"139.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n<text text-anchor=\"start\" x=\"143\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = play</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M219.49,-341.91C214.87,-333.2 209.95,-323.9 205.17,-314.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"208.25,-313.22 200.47,-306.02 202.06,-316.5 208.25,-313.22\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#f8e0ce\" stroke=\"black\" d=\"M348,-306C348,-306 258,-306 258,-306 252,-306 246,-300 246,-294 246,-294 246,-235 246,-235 246,-229 252,-223 258,-223 258,-223 348,-223 348,-223 354,-223 360,-229 360,-235 360,-235 360,-294 360,-294 360,-300 354,-306 348,-306\"/>\n<text text-anchor=\"start\" x=\"270.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">temp ≤ 1.5</text>\n<text text-anchor=\"start\" x=\"271\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.49</text>\n<text text-anchor=\"start\" x=\"265.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"263.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 3]</text>\n<text text-anchor=\"start\" x=\"254\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = not_play</text>\n</g>\n<!-- 2&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>2&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M262.51,-341.91C267.13,-333.2 272.05,-323.9 276.83,-314.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"279.94,-316.5 281.53,-306.02 273.75,-313.22 279.94,-316.5\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M102,-179.5C102,-179.5 12,-179.5 12,-179.5 6,-179.5 0,-173.5 0,-167.5 0,-167.5 0,-123.5 0,-123.5 0,-117.5 6,-111.5 12,-111.5 12,-111.5 102,-111.5 102,-111.5 108,-111.5 114,-117.5 114,-123.5 114,-123.5 114,-167.5 114,-167.5 114,-173.5 108,-179.5 102,-179.5\"/>\n<text text-anchor=\"start\" x=\"29\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"19.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"17.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = not_play</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M136.67,-222.91C124.48,-211.21 111.18,-198.46 99,-186.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"101.22,-184.06 91.58,-179.67 96.38,-189.11 101.22,-184.06\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M215.5,-179.5C215.5,-179.5 144.5,-179.5 144.5,-179.5 138.5,-179.5 132.5,-173.5 132.5,-167.5 132.5,-167.5 132.5,-123.5 132.5,-123.5 132.5,-117.5 138.5,-111.5 144.5,-111.5 144.5,-111.5 215.5,-111.5 215.5,-111.5 221.5,-111.5 227.5,-117.5 227.5,-123.5 227.5,-123.5 227.5,-167.5 227.5,-167.5 227.5,-173.5 221.5,-179.5 215.5,-179.5\"/>\n<text text-anchor=\"start\" x=\"152\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"142.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"140.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n<text text-anchor=\"start\" x=\"144\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = play</text>\n</g>\n<!-- 3&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>3&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M179.35,-222.91C179.44,-212.2 179.54,-200.62 179.63,-189.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"183.13,-189.7 179.72,-179.67 176.13,-189.64 183.13,-189.7\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M348,-179.5C348,-179.5 258,-179.5 258,-179.5 252,-179.5 246,-173.5 246,-167.5 246,-167.5 246,-123.5 246,-123.5 246,-117.5 252,-111.5 258,-111.5 258,-111.5 348,-111.5 348,-111.5 354,-111.5 360,-117.5 360,-123.5 360,-123.5 360,-167.5 360,-167.5 360,-173.5 354,-179.5 348,-179.5\"/>\n<text text-anchor=\"start\" x=\"275\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"265.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"263.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n<text text-anchor=\"start\" x=\"254\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = not_play</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M303,-222.91C303,-212.2 303,-200.62 303,-189.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"306.5,-189.67 303,-179.67 299.5,-189.67 306.5,-189.67\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#bddef6\" stroke=\"black\" d=\"M464,-187C464,-187 390,-187 390,-187 384,-187 378,-181 378,-175 378,-175 378,-116 378,-116 378,-110 384,-104 390,-104 390,-104 464,-104 464,-104 470,-104 476,-110 476,-116 476,-116 476,-175 476,-175 476,-181 470,-187 464,-187\"/>\n<text text-anchor=\"start\" x=\"386\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">weather ≤ 1.5</text>\n<text text-anchor=\"start\" x=\"395\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\n<text text-anchor=\"start\" x=\"389.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"387.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 3]</text>\n<text text-anchor=\"start\" x=\"391\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = play</text>\n</g>\n<!-- 6&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>6&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M346.02,-222.91C355.93,-213.56 366.55,-203.54 376.73,-193.93\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"379.18,-196.43 384.05,-187.02 374.38,-191.34 379.18,-196.43\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M400.5,-68C400.5,-68 329.5,-68 329.5,-68 323.5,-68 317.5,-62 317.5,-56 317.5,-56 317.5,-12 317.5,-12 317.5,-6 323.5,0 329.5,0 329.5,0 400.5,0 400.5,0 406.5,0 412.5,-6 412.5,-12 412.5,-12 412.5,-56 412.5,-56 412.5,-62 406.5,-68 400.5,-68\"/>\n<text text-anchor=\"start\" x=\"329.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"327.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"325.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n<text text-anchor=\"start\" x=\"329\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = play</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M403.91,-103.73C399.01,-95.06 393.82,-85.9 388.88,-77.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"391.83,-75.28 383.85,-68.3 385.74,-78.73 391.83,-75.28\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M533,-68C533,-68 443,-68 443,-68 437,-68 431,-62 431,-56 431,-56 431,-12 431,-12 431,-6 437,0 443,0 443,0 533,0 533,0 539,0 545,-6 545,-12 545,-12 545,-56 545,-56 545,-62 539,-68 533,-68\"/>\n<text text-anchor=\"start\" x=\"460\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"450.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"448.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n<text text-anchor=\"start\" x=\"439\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = not_play</text>\n</g>\n<!-- 8&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>8&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M449.71,-103.73C454.54,-95.06 459.65,-85.9 464.5,-77.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"467.64,-78.74 469.45,-68.3 461.53,-75.33 467.64,-78.74\"/>\n</g>\n</g>\n</svg>\n"
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(df[[\"weather_encoded\",\"temp_encoded\"]],df[\"Y\"])\n",
    "y_pred = decision_tree.predict(x_test)\n",
    "\n",
    "gv_data = export_graphviz(decision_tree, out_file=None,\n",
    "                                        feature_names=[\"weather\",\"temp\"],\n",
    "                                        class_names=[\"not_play\",\"play\"],\n",
    "                                        filled=True, rounded=True,\n",
    "                                        special_characters=True)\n",
    "graph = graphviz.Source(gv_data)\n",
    "graph\n",
    "\n",
    "def train_decision_tree(x, y):\n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    decision_tree.fit(x, y)\n",
    "    return decision_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1, 1, 1, 1, 1, 1, 0, 0, 0])"
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "svm_classifier = svm.SVC(kernel='linear')\n",
    "svm_classifier.fit(df[[\"weather_encoded\",\"temp_encoded\"]],df[\"Y\"])\n",
    "svm_classifier.predict(x_test)\n",
    "\n",
    "def train_svm(x,y):\n",
    "    svm_classifier = svm.SVC(kernel='linear')\n",
    "    svm_classifier.fit(x,y)\n",
    "    return svm_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitvenvvenv7c8b5f64282a4e90a5603bde2787a492",
   "display_name": "Python 3.8.2 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}